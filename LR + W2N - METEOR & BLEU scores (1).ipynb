{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.nltk.org/api/nltk.translate.meteor_score.html\n",
    "#https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "#https://www.geeksforgeeks.org/python-how-to-make-a-terminal-progress-bar-using-tqdm/\n",
    "#https://stackoverflow.com/questions/70947892/best-smoothing-function-to-use-in-nltk-corpus-bleu-method\n",
    "#https://stackoverflow.com/questions/68926574/i-compare-two-identical-sentences-with-bleu-nltk-and-dont-get-1-0-why\n",
    "#https://stackoverflow.com/questions/77043285/nltk-sentence-bleu-returns-0-while-evaluating-chinese-sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/marilu/training_dfs/feeling_thinking.csv',\n",
       " '/home/marilu/training_dfs/extrovert_introvert.csv',\n",
       " '/home/marilu/training_dfs/nationality.csv',\n",
       " '/home/marilu/training_dfs/birth_year.csv',\n",
       " '/home/marilu/training_dfs/gender.csv',\n",
       " '/home/marilu/training_dfs/political_leaning.csv',\n",
       " '/home/marilu/training_dfs/sensing_intuitive.csv',\n",
       " '/home/marilu/training_dfs/judging_perceiving.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs = list(set(glob('/home/marilu/training_dfs/*.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*_ft.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*balanced.csv')))\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>political_leaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>You can \"buy\" the show and stream it through t...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>me want to play Q*bert Holy shit, based Alex J...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>Shouldn't rely on any external services or per...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>PR to a specific person. Usually that just mea...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>This article's intention is clear that they wa...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114458</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>hard as I have to go out of my way to find med...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114459</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>WORLD WILL BE MINE! Well if you read it, then ...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114460</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>Wow super passing there sir. I’m jelly. Aesthe...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114461</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>compliment your face. Okay fair enough. I supp...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114462</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>and try to live yours lest you spend it all wa...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114463 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          auhtor_ID                                               post  \\\n",
       "0       t2_7ramzeng  You can \"buy\" the show and stream it through t...   \n",
       "1       t2_7ramzeng  me want to play Q*bert Holy shit, based Alex J...   \n",
       "2       t2_7ramzeng  Shouldn't rely on any external services or per...   \n",
       "3       t2_7ramzeng  PR to a specific person. Usually that just mea...   \n",
       "4       t2_7ramzeng  This article's intention is clear that they wa...   \n",
       "...             ...                                                ...   \n",
       "114458     t2_vi35s  hard as I have to go out of my way to find med...   \n",
       "114459     t2_vi35s  WORLD WILL BE MINE! Well if you read it, then ...   \n",
       "114460   t2_vyu81f9  Wow super passing there sir. I’m jelly. Aesthe...   \n",
       "114461   t2_vyu81f9  compliment your face. Okay fair enough. I supp...   \n",
       "114462   t2_vyu81f9  and try to live yours lest you spend it all wa...   \n",
       "\n",
       "       political_leaning  \n",
       "0                  right  \n",
       "1                  right  \n",
       "2                  right  \n",
       "3                  right  \n",
       "4                  right  \n",
       "...                  ...  \n",
       "114458            center  \n",
       "114459            center  \n",
       "114460              left  \n",
       "114461              left  \n",
       "114462              left  \n",
       "\n",
       "[114463 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_dirs[5])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X_post = vec.fit_transform(data['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_political = data['political_leaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_post, y_political, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.65      0.77      0.71     14160\n",
      "        left       0.69      0.61      0.65      9625\n",
      "       right       0.73      0.63      0.68     10554\n",
      "\n",
      "    accuracy                           0.68     34339\n",
      "   macro avg       0.69      0.67      0.68     34339\n",
      "weighted avg       0.69      0.68      0.68     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the posts\n",
    "tokenized_posts = data['post'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create word-to-number mapping\n",
    "word_to_num = {}\n",
    "current_num = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in tokenized_posts:\n",
    "    for word in post:\n",
    "        if word not in word_to_num:\n",
    "            word_to_num[word] = current_num\n",
    "            current_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace words with numbers in the dataset\n",
    "obfuscated_data = data.copy()\n",
    "obfuscated_data['obfuscated_post'] = tokenized_posts.apply(lambda post: ' '.join(str(word_to_num[word]) for word in post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_new = TfidfVectorizer()\n",
    "X_post_new = vec.fit_transform(obfuscated_data['obfuscated_post'])\n",
    "y_political_new = obfuscated_data['political_leaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_post_new, y_political_new, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(max_iter=6000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_w2n = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.66      0.78      0.71     14160\n",
      "        left       0.70      0.62      0.66      9625\n",
      "       right       0.73      0.63      0.68     10554\n",
      "\n",
      "    accuracy                           0.69     34339\n",
      "   macro avg       0.70      0.67      0.68     34339\n",
      "weighted avg       0.69      0.69      0.68     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, predictions_w2n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import meteor_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = data['post'].tolist()\n",
    "obfuscated_texts = obfuscated_data['obfuscated_post'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11446/11446 [1:28:37<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#choose sample size of 10%\n",
    "sample_size = int(0.1 * len(original_texts)) \n",
    "\n",
    "sample_original_texts = original_texts[:sample_size]\n",
    "sample_obfuscated_texts = obfuscated_texts[:sample_size]\n",
    "\n",
    "#METEOR-score of sample size, comparing obfuscated and original text       \n",
    "meteor_scores = []\n",
    "with tqdm(total=sample_size) as pbar:\n",
    "    for orig_text, geo_text in zip(sample_original_texts, sample_obfuscated_texts):\n",
    "        meteor_scores.append(meteor_score.single_meteor_score(orig_text, geo_text))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR-score: 0.0021900821457238244\n"
     ]
    }
   ],
   "source": [
    "meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "print(\"METEOR-score:\", meteor_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_references = [[text.split()] for text in sample_original_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_obfuscated = [text.split() for text in sample_obfuscated_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/guest/.local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/guest/.local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/guest/.local/lib/python3.6/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████| 1/1 [01:27<00:00, 87.42s/it]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=1) as pbar:\n",
    "    sample_blue_score = corpus_bleu(sample_references, sample_obfuscated)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE-score: 3.802398089452196e-232\n"
     ]
    }
   ],
   "source": [
    "print(\"BLUE-score:\", sample_blue_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "sample_references = [[text.split()] for text in sample_original_texts]\n",
    "\n",
    "sample_obfuscated = [text.split() for text in sample_obfuscated_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing function\n",
    "smoother = SmoothingFunction().method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:24<00:00, 84.51s/it]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=1) as pbar:\n",
    "    sample_blue_score = corpus_bleu(sample_references, sample_obfuscated, smoothing_function=smoother)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE-score: 1.4053529525523834e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"BLUE-score:\", sample_blue_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
