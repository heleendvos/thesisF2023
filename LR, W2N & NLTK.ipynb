{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sources code\n",
    "#https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/\n",
    "#https://huggingface.co/docs/tokenizers/pipeline\n",
    "#https://stackoverflow.com/questions/41912083/nltk-tokenize-faster-way\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "#https://www.nltk.org/howto/wordnet.html\n",
    "#https://subscription.packtpub.com/book/data/9781782167853/1/ch01lvl1sec15/looking-up-lemmas-and-synonyms-in-wordnet\n",
    "#https://www.kaggle.com/code/roblexnana/nlp-with-nltk-tokenizing-text-and-wordnet-basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/marilu/training_dfs/feeling_thinking.csv',\n",
       " '/home/marilu/training_dfs/judging_perceiving.csv',\n",
       " '/home/marilu/training_dfs/nationality.csv',\n",
       " '/home/marilu/training_dfs/gender.csv',\n",
       " '/home/marilu/training_dfs/birth_year.csv',\n",
       " '/home/marilu/training_dfs/sensing_intuitive.csv',\n",
       " '/home/marilu/training_dfs/extrovert_introvert.csv',\n",
       " '/home/marilu/training_dfs/political_leaning.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs = list(set(glob('/home/marilu/training_dfs/*.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*_ft.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*balanced.csv')))\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>political_leaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>You can \"buy\" the show and stream it through t...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>me want to play Q*bert Holy shit, based Alex J...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>Shouldn't rely on any external services or per...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>PR to a specific person. Usually that just mea...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>This article's intention is clear that they wa...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114458</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>hard as I have to go out of my way to find med...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114459</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>WORLD WILL BE MINE! Well if you read it, then ...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114460</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>Wow super passing there sir. I’m jelly. Aesthe...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114461</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>compliment your face. Okay fair enough. I supp...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114462</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>and try to live yours lest you spend it all wa...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114463 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          auhtor_ID                                               post  \\\n",
       "0       t2_7ramzeng  You can \"buy\" the show and stream it through t...   \n",
       "1       t2_7ramzeng  me want to play Q*bert Holy shit, based Alex J...   \n",
       "2       t2_7ramzeng  Shouldn't rely on any external services or per...   \n",
       "3       t2_7ramzeng  PR to a specific person. Usually that just mea...   \n",
       "4       t2_7ramzeng  This article's intention is clear that they wa...   \n",
       "...             ...                                                ...   \n",
       "114458     t2_vi35s  hard as I have to go out of my way to find med...   \n",
       "114459     t2_vi35s  WORLD WILL BE MINE! Well if you read it, then ...   \n",
       "114460   t2_vyu81f9  Wow super passing there sir. I’m jelly. Aesthe...   \n",
       "114461   t2_vyu81f9  compliment your face. Okay fair enough. I supp...   \n",
       "114462   t2_vyu81f9  and try to live yours lest you spend it all wa...   \n",
       "\n",
       "       political_leaning  \n",
       "0                  right  \n",
       "1                  right  \n",
       "2                  right  \n",
       "3                  right  \n",
       "4                  right  \n",
       "...                  ...  \n",
       "114458            center  \n",
       "114459            center  \n",
       "114460              left  \n",
       "114461              left  \n",
       "114462              left  \n",
       "\n",
       "[114463 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_dirs[7])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X_post = vec.fit_transform(data['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_political = data['political_leaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_post, y_political, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.65      0.77      0.71     14160\n",
      "        left       0.69      0.61      0.65      9625\n",
      "       right       0.73      0.63      0.68     10554\n",
      "\n",
      "    accuracy                           0.68     34339\n",
      "   macro avg       0.69      0.67      0.68     34339\n",
      "weighted avg       0.69      0.68      0.68     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the posts\n",
    "tokenized_posts = data['post'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create word-to-number mapping\n",
    "word_to_num = {}\n",
    "current_num = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in tokenized_posts:\n",
    "    for word in post:\n",
    "        if word not in word_to_num:\n",
    "            word_to_num[word] = current_num\n",
    "            current_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace words with numbers in the dataset\n",
    "obfuscated_data = data.copy()\n",
    "obfuscated_data['obfuscated_post'] = tokenized_posts.apply(lambda post: ' '.join(str(word_to_num[word]) for word in post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_new = TfidfVectorizer()\n",
    "X_post_new = vec.fit_transform(obfuscated_data['obfuscated_post'])\n",
    "y_political_new = obfuscated_data['political_leaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_post_new, y_political_new, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(max_iter=6000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.66      0.78      0.71     14160\n",
      "        left       0.70      0.62      0.66      9625\n",
      "       right       0.73      0.63      0.68     10554\n",
      "\n",
      "    accuracy                           0.69     34339\n",
      "   macro avg       0.70      0.67      0.68     34339\n",
      "weighted avg       0.69      0.69      0.68     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>political_leaning</th>\n",
       "      <th>obfuscated_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>You can \"buy\" the show and stream it through t...</td>\n",
       "      <td>right</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 4 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>me want to play Q*bert Holy shit, based Alex J...</td>\n",
       "      <td>right</td>\n",
       "      <td>146 760 59 761 762 763 764 765 766 767 768 769...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>Shouldn't rely on any external services or per...</td>\n",
       "      <td>right</td>\n",
       "      <td>1295 1296 192 569 1297 1227 611 1298 1047 203 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>PR to a specific person. Usually that just mea...</td>\n",
       "      <td>right</td>\n",
       "      <td>1690 59 94 1527 1730 1731 70 72 1399 94 1732 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>This article's intention is clear that they wa...</td>\n",
       "      <td>right</td>\n",
       "      <td>387 2145 2146 19 2147 70 164 760 59 2148 94 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114458</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>hard as I have to go out of my way to find med...</td>\n",
       "      <td>center</td>\n",
       "      <td>1631 856 17 93 59 132 99 52 178 195 59 538 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114459</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>WORLD WILL BE MINE! Well if you read it, then ...</td>\n",
       "      <td>center</td>\n",
       "      <td>48885 29707 32168 2045829 7407 211 106 1570 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114460</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>Wow super passing there sir. I’m jelly. Aesthe...</td>\n",
       "      <td>left</td>\n",
       "      <td>30091 7916 621 27 45274 707 20277 568473 33419...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114461</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>compliment your face. Okay fair enough. I supp...</td>\n",
       "      <td>left</td>\n",
       "      <td>79019 216 10651 24245 8183 1632 17 1083 44 146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114462</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>and try to live yours lest you spend it all wa...</td>\n",
       "      <td>left</td>\n",
       "      <td>6 378 59 2502 15505 45981 106 2004 8 175 4730 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114463 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          auhtor_ID                                               post  \\\n",
       "0       t2_7ramzeng  You can \"buy\" the show and stream it through t...   \n",
       "1       t2_7ramzeng  me want to play Q*bert Holy shit, based Alex J...   \n",
       "2       t2_7ramzeng  Shouldn't rely on any external services or per...   \n",
       "3       t2_7ramzeng  PR to a specific person. Usually that just mea...   \n",
       "4       t2_7ramzeng  This article's intention is clear that they wa...   \n",
       "...             ...                                                ...   \n",
       "114458     t2_vi35s  hard as I have to go out of my way to find med...   \n",
       "114459     t2_vi35s  WORLD WILL BE MINE! Well if you read it, then ...   \n",
       "114460   t2_vyu81f9  Wow super passing there sir. I’m jelly. Aesthe...   \n",
       "114461   t2_vyu81f9  compliment your face. Okay fair enough. I supp...   \n",
       "114462   t2_vyu81f9  and try to live yours lest you spend it all wa...   \n",
       "\n",
       "       political_leaning                                    obfuscated_post  \n",
       "0                  right  1 2 3 4 5 6 7 8 9 10 11 4 12 13 14 15 16 17 18...  \n",
       "1                  right  146 760 59 761 762 763 764 765 766 767 768 769...  \n",
       "2                  right  1295 1296 192 569 1297 1227 611 1298 1047 203 ...  \n",
       "3                  right  1690 59 94 1527 1730 1731 70 72 1399 94 1732 1...  \n",
       "4                  right  387 2145 2146 19 2147 70 164 760 59 2148 94 21...  \n",
       "...                  ...                                                ...  \n",
       "114458            center  1631 856 17 93 59 132 99 52 178 195 59 538 100...  \n",
       "114459            center  48885 29707 32168 2045829 7407 211 106 1570 10...  \n",
       "114460              left  30091 7916 621 27 45274 707 20277 568473 33419...  \n",
       "114461              left  79019 216 10651 24245 8183 1632 17 1083 44 146...  \n",
       "114462              left  6 378 59 2502 15505 45981 106 2004 8 175 4730 ...  \n",
       "\n",
       "[114463 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obfuscated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace words with their synonyms\n",
    "def replace_synonyms(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        syns = wordnet.synsets(token)\n",
    "        if syns:\n",
    "            synonym = syns[0].lemmas()[0].name()\n",
    "            new_tokens.append(synonym)\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    return ' '.join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply obfuscation to the posts\n",
    "obfuscated_data['paraphrased_post'] = data['post'].apply(replace_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paraphrased = obfuscated_data['paraphrased_post']\n",
    "y_paraphrased = obfuscated_data['political_leaning']\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_paraphrased, y_paraphrased, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_paraphrased = TfidfVectorizer()\n",
    "X_train_vec_p = vec_paraphrased.fit_transform(X_train_p)\n",
    "X_test_vec_p = vec_paraphrased.transform(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_p = LogisticRegression(max_iter=6000)\n",
    "classifier_p.fit(X_train_vec_p, y_train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_p = classifier_p.predict(X_test_vec_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for paraphrased posts:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.65      0.76      0.70     14160\n",
      "        left       0.68      0.61      0.64      9625\n",
      "       right       0.72      0.63      0.67     10554\n",
      "\n",
      "    accuracy                           0.68     34339\n",
      "   macro avg       0.68      0.66      0.67     34339\n",
      "weighted avg       0.68      0.68      0.67     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for paraphrased posts:\")\n",
    "print(classification_report(y_test_p, predictions_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         You can `` bargain '' the show and stream info...\n",
       "1         Maine privation to play Q * bert holy_place cr...\n",
       "2         Should n't trust on any external services Oreg...\n",
       "3         praseodymium to angstrom particular person . n...\n",
       "4         This article 's purpose be clear that they pri...\n",
       "                                ...                        \n",
       "114458    difficult arsenic iodine rich_person to go out...\n",
       "114459    universe volition beryllium mine ! well if you...\n",
       "114460    belly_laugh superintendent pass there sir . io...\n",
       "114461    compliment your face . O.K. carnival enough . ...\n",
       "114462    and attempt to populate yours fifty you spend ...\n",
       "Name: paraphrased_post, Length: 114463, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_paraphrased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
