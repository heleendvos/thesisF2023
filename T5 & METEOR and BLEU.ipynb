{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-how-to-make-a-terminal-progress-bar-using-tqdm/\n",
    "#https://huggingface.co/learn/nlp-course/chapter6/8?fw=pt\n",
    "#https://stackoverflow.com/questions/21714400/enumerate-on-specific-items-of-a-list\n",
    "#https://www.kaggle.com/code/tuckerarrants/text-generation-with-huggingface-gpt2\n",
    "#https://github.com/ultralytics/ultralytics/issues/2143\n",
    "#https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "#https://www.nltk.org/api/nltk.translate.meteor_score.html\n",
    "#https://huggingface.co/docs/transformers/model_doc/t5\n",
    "#https://huggingface.co/transformers/v3.0.2/_modules/transformers/modeling_t5.html#T5ForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/data/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/guest/.local/lib/python3.6/site-packages (4.64.0)\n",
      "Requirement already satisfied: importlib-resources in /home/guest/.local/lib/python3.6/site-packages (from tqdm) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/guest/.local/lib/python3.6/site-packages (from importlib-resources->tqdm) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/marilu/training_dfs/extrovert_introvert.csv',\n",
       " '/home/marilu/training_dfs/judging_perceiving.csv',\n",
       " '/home/marilu/training_dfs/sensing_intuitive.csv',\n",
       " '/home/marilu/training_dfs/feeling_thinking.csv',\n",
       " '/home/marilu/training_dfs/nationality.csv',\n",
       " '/home/marilu/training_dfs/gender.csv',\n",
       " '/home/marilu/training_dfs/birth_year.csv',\n",
       " '/home/marilu/training_dfs/political_leaning.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs = list(set(glob('/home/marilu/training_dfs/*.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*_ft.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*balanced.csv')))\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>political_leaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>You can \"buy\" the show and stream it through t...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>me want to play Q*bert Holy shit, based Alex J...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>Shouldn't rely on any external services or per...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>PR to a specific person. Usually that just mea...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>This article's intention is clear that they wa...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114458</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>hard as I have to go out of my way to find med...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114459</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>WORLD WILL BE MINE! Well if you read it, then ...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114460</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>Wow super passing there sir. I’m jelly. Aesthe...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114461</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>compliment your face. Okay fair enough. I supp...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114462</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>and try to live yours lest you spend it all wa...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114463 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          auhtor_ID                                               post  \\\n",
       "0       t2_7ramzeng  You can \"buy\" the show and stream it through t...   \n",
       "1       t2_7ramzeng  me want to play Q*bert Holy shit, based Alex J...   \n",
       "2       t2_7ramzeng  Shouldn't rely on any external services or per...   \n",
       "3       t2_7ramzeng  PR to a specific person. Usually that just mea...   \n",
       "4       t2_7ramzeng  This article's intention is clear that they wa...   \n",
       "...             ...                                                ...   \n",
       "114458     t2_vi35s  hard as I have to go out of my way to find med...   \n",
       "114459     t2_vi35s  WORLD WILL BE MINE! Well if you read it, then ...   \n",
       "114460   t2_vyu81f9  Wow super passing there sir. I’m jelly. Aesthe...   \n",
       "114461   t2_vyu81f9  compliment your face. Okay fair enough. I supp...   \n",
       "114462   t2_vyu81f9  and try to live yours lest you spend it all wa...   \n",
       "\n",
       "       political_leaning  \n",
       "0                  right  \n",
       "1                  right  \n",
       "2                  right  \n",
       "3                  right  \n",
       "4                  right  \n",
       "...                  ...  \n",
       "114458            center  \n",
       "114459            center  \n",
       "114460              left  \n",
       "114461              left  \n",
       "114462              left  \n",
       "\n",
       "[114463 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_dirs[7])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X_post = vec.fit_transform(data['post'])\n",
    "y_political = data['political_leaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_post, y_political, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(max_iter=6000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.65      0.77      0.71     14160\n",
      "        left       0.69      0.61      0.65      9625\n",
      "       right       0.73      0.63      0.68     10554\n",
      "\n",
      "    accuracy                           0.68     34339\n",
      "   macro avg       0.69      0.67      0.68     34339\n",
      "weighted avg       0.69      0.68      0.68     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"political leaning.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in political leaning.txt\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"w\") as file:\n",
    "    for prediction in predictions:\n",
    "        file.write(str(prediction) + \"\\n\")  \n",
    "print(f\"Results are saved in {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obfuscate_subset(texts):\n",
    "    #choose T5 model: Base\n",
    "    model_name = 't5-base'\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    #Obfuscate a sample of 200 inctances\n",
    "    obfuscated_texts = []\n",
    "\n",
    "    with tqdm(total=200) as pbar:  \n",
    "        for idx, text in enumerate(texts):\n",
    "            if idx >= 200:\n",
    "                break  \n",
    "            text = \"obfuscate: \" + text\n",
    "            inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "            outputs = model.generate(inputs, max_length=150, num_return_sequences=1, num_beams=5, temperature=0.9)\n",
    "            decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            obfuscated_texts.append(decoded_output)\n",
    "            pbar.update(1) \n",
    "\n",
    "    return obfuscated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_posts = data.loc[y_test.index]['post'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [24:15<00:00,  7.28s/it]\n"
     ]
    }
   ],
   "source": [
    "#obfuscate 200 instances \n",
    "X_test_obfuscated_subset = obfuscate_subset(X_test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_obfuscated_vectorized = vec.transform(X_test_obfuscated_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_subset = y_test[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on obfuscated test set (subset of 200 instances):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.44      0.74      0.56        74\n",
      "        left       0.55      0.31      0.40        58\n",
      "       right       0.56      0.35      0.43        68\n",
      "\n",
      "    accuracy                           0.48       200\n",
      "   macro avg       0.52      0.47      0.46       200\n",
      "weighted avg       0.51      0.48      0.47       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation on obfuscated testset (200 instances)\n",
    "predictions_obfuscated = classifier.predict(X_test_obfuscated_vectorized)\n",
    "print(\"Classification report on obfuscated test set (subset of 200 instances):\")\n",
    "print(classification_report(y_test_subset, predictions_obfuscated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"paraphrasing results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in paraphrasing results.txt\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"w\") as file:\n",
    "    for prediction in predictions:\n",
    "        file.write(str(prediction) + \"\\n\")  \n",
    "print(f\"Results are saved in {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    for text in X_test_obfuscated_subset:\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = data.loc[y_test.index]['post'].tolist()[:200] \n",
    "obfuscated_texts = X_test_obfuscated_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_scores = [meteor_score.single_meteor_score(orig_text, geo_text) for orig_text, geo_text in zip(original_texts, obfuscated_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR-score: 0.024501063351237348\n"
     ]
    }
   ],
   "source": [
    "meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "print(\"METEOR-score:\", meteor_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [[text.split()] for text in original_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfuscated = [text.split() for text in obfuscated_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUE-score: 1.969577110410123e-11\n"
     ]
    }
   ],
   "source": [
    "blue_score = corpus_bleu(references, obfuscated)\n",
    "print(\"BLUE-score:\", blue_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
